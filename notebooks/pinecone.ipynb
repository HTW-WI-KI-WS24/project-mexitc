{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pincecone first implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\karla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\karla\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from pdf into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datas\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Vector database\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "# Llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema import SystemMessage, ChatMessage\n",
    "\n",
    "#agents\n",
    "from langchain.agents.types import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ.clear()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 3112 characters in your document\n"
     ]
    }
   ],
   "source": [
    "#use your file \n",
    "loader = PyPDFLoader(\"../ruy.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 4 documents\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedings and upload to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'),chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key= os.getenv('PINECONE_API_KEY'),  # find at app.pinecone.io\n",
    "    environment= os.getenv('PINECONE_ENVIRONMENT')   # next to api key in console\n",
    ")\n",
    "index = 'digital-twin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from vector database with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pinecone.Index(index)\n",
    "text_field = \"text\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    idx,\n",
    "    embeddings,\n",
    "    text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTopic = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"What experience does Ruy have related to {topic}? Give me an overview and a detailed list of technologies used in his {topic} experience\",\n",
    "    )\n",
    "\n",
    "promptLanguage= PromptTemplate(\n",
    "    input_variables=[\"language\"],\n",
    "    template=\"Is {language} within the programming lnguages Ruy can use? And show me an example of how has he used it\",\n",
    "    )\n",
    "\n",
    "promptFramework = PromptTemplate(\n",
    "    input_variables=[\"framework\"],\n",
    "    template=\"Does Ruy have any expierence using {framework}? Describe the experiences\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name='gpt-4',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step back prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: _Py_HashRandomization_Init: failed to get random numbers to initialize Python\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain import hub\n",
    "\n",
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few_shots examples and promtps\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"input\": \"What programming languages are you proficient in?\",\n",
    "        \"output\": \"List the programming languages you are proficient in.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Tell me about a project where you worked collaboratively with a team.\",\n",
    "        \"output\": \"Describe a project where you collaborated with a team, including your role and contributions.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How do you stay updated with the latest technologies in the field?\",\n",
    "        \"output\": \"Explain how you stay informed about the latest technologies and industry trends.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Tell me about a challenging problem you encountered during a project and how you solved it.\",\n",
    "        \"output\": \"Describe a challenging problem you faced during a project and the steps you took to solve it.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-back prompt template\n",
    "step_back_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"),\n",
    "    few_shot_prompt,  # Include the few-shot examples\n",
    "    (\"user\", \"{question}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_back_retriever(query):\n",
    "    return step_back_prompt | ChatOpenAI(temperature=0) | retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain definition\n",
    "chain = {\n",
    "    # Retrieve context using the normal question\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Retrieve context using the step-back question\n",
    "    \"step_back_context\": RunnableLambda(lambda x: x['question']) | step_back_retriever,\n",
    "    # Pass on the question\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./StudentPrompt.txt\")\n",
    "\n",
    "StudentPrompt = loader.load()[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"qa-student\",\n",
    "        func=qa.run,\n",
    "        description=\"Answer questions related to the student\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=conversational_memory,\n",
    "    system_message=StudentPrompt,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": StudentPrompt\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run w normal_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Hello! I'm Ruy Guzman. I am a dedicated and enthusiastic student with a strong academic track record in my field of study. Throughout my academic journey, I've concentrated my efforts on honing skills relevant to the tech industry. Not only have I focused on developing hard skills such as programming languages and data analysis, but I've also built a firm foundation of soft skills, including teamwork, communication, and problem-solving. I'm seeking a position where I can contribute these skills and learn new ones. I believe in constantly challenging myself to grow and adapt, which, I think, holds the key to building a successful career in tech. I'm excited by the prospect of working with your esteemed organization and contributing to your team.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm Ruy Guzman. I am a dedicated and enthusiastic student with a strong academic track record in my field of study. Throughout my academic journey, I've concentrated my efforts on honing skills relevant to the tech industry. Not only have I focused on developing hard skills such as programming languages and data analysis, but I've also built a firm foundation of soft skills, including teamwork, communication, and problem-solving. I'm seeking a position where I can contribute these skills and learn new ones. I believe in constantly challenging myself to grow and adapt, which, I think, holds the key to building a successful career in tech. I'm excited by the prospect of working with your esteemed organization and contributing to your team.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"Hi, Im a recruiter for a tech company. Can you briefly introduce yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"While my primary focus has been on software development and data analysis, I do understand the significance of DevOps culture in facilitating effective collaboration within the tech environment. I have a basic understanding of containerization technologies such as Docker and have familiarised myself with cloud services like AWS. Moreover, in one of my recent academic projects, I worked closely with a DevOps engineer which gave me invaluable exposure to CI/CD pipelines. Although I'm not an expert, I am very keen to delve deeper into the DevOps arena. I truly believe that my willingness to learn combined with my foundational knowledge, could bear fruitful results for your team given the opportunity.\" \n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"While my primary focus has been on software development and data analysis, I do understand the significance of DevOps culture in facilitating effective collaboration within the tech environment. I have a basic understanding of containerization technologies such as Docker and have familiarised myself with cloud services like AWS. Moreover, in one of my recent academic projects, I worked closely with a DevOps engineer which gave me invaluable exposure to CI/CD pipelines. Although I'm not an expert, I am very keen to delve deeper into the DevOps arena. I truly believe that my willingness to learn combined with my foundational knowledge, could bear fruitful results for your team given the opportunity.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"I'm looking for a DevOps engineer, do you have any experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"qa-student\",\n",
      "    \"action_input\": \"Production engineer experience\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRuy Guzman Camacho has experience as a Production Engineering Fellow in the Major League Hacking Fellowship from May 2022 to August 2022. During this time, he completed a 12-week curriculum that covered core topics in Production Engineering, along with attending events and workshops hosted by industry experts. He developed an open-source personal portfolio website using technologies such as Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. He also automated testing and deployment using CI/CD with GitHub actions and set up monitoring environments using Prometheus and Grafana.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"As a matter of fact, I do have experience in Production Engineering. Most of my practical experience was gained during my fellowship with Major League Hacking from May to August 2022. The 12-week curriculum covered core topics in Production Engineering and provided me with invaluable hands-on experience. I had the opportunity to develop an open-source personal portfolio website using a range of technologies including Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. Moreover, I gained practical experience in automating testing and deployment using CI/CD with GitHub actions and setting up monitoring environments using Prometheus and Grafana.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As a matter of fact, I do have experience in Production Engineering. Most of my practical experience was gained during my fellowship with Major League Hacking from May to August 2022. The 12-week curriculum covered core topics in Production Engineering and provided me with invaluable hands-on experience. I had the opportunity to develop an open-source personal portfolio website using a range of technologies including Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. Moreover, I gained practical experience in automating testing and deployment using CI/CD with GitHub actions and setting up monitoring environments using Prometheus and Grafana.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"I'm looking for a Production engineer, do you have any experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From the information provided, Ruy Guzman Camacho has experience in DevOps from his time as an MLH Production Engineering Fellow at Major League Hacking Fellowship during the summer of 2022. \\n\\nDuring this fellowship, he took part in 12 weeks of curriculum-based learning that covered core Production Engineering topics. Additionally, Ruy developed an open source personal portfolio website that allowed him to make practical use of several DevOps-related skills and technologies.\\n\\nIn more detail, the technologies he used during his fellowship include:\\n\\n1. Python: A general-purpose programming language that Ruy likely used for scripting and task automation.\\n2. Flask & Jinja: These are both Python libraries. Flask is a web framework while Jinja is a template engine. Ruy likely used them for developing the backend of his personal portfolio website.\\n3. Tailwind CSS: This is a utility-first CSS framework used for building custom user interfaces, which Ruy likely used for front-end development.\\n4. MySQL: This is a relational database management system. Ruy would have used MySQL for managing the data of his personal portfolio website.\\n5. Nginx: Nginx is a powerful web server, reverse proxy server, and load balancer. Ruy could have used this technology for handling requests to his website and ensuring optimal performance.\\n6. Unittest: This is a testing framework in Python. Ruy used it for automating testing processes.\\n7. Docker: Docker is a platform designed to make it easier to create, deploy, and run applications using containers. Ruy used Docker to contain his application along with its dependencies.\\n8. GitHub Actions: GitHub actions provides CI/CD automation directly within GitHub. Ruy used GitHub actions for automating his software workflows, including testing and deployment.\\n9. Google Maps API: Ruy used this web service from Google to feature and interact with maps on his personal portfolio website.\\n10. Prometheus and Grafana: These are open-source systems monitoring and visualization tools. Ruy used them to set up monitoring environments for his project.\\n\\nFrom this, it's evident that Ruy has a broad and deep understanding of different DevOps-related technologies.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptTopic.format(topic=\"DevOps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, Ruby is within the programming languages that Ruy can use. He has experience in software development with Ruby on Rails according to the information provided. Unfortunately, we can't provide specific examples of how he has used Ruby, as the context does not give these details.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptLanguage.format(language=\"Ruby\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context provided does not mention any experience that Ruy Guzman Camacho has with using React.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptFramework.format(framework=\"React\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
