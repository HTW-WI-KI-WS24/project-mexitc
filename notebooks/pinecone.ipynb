{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pincecone first implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install pinecone-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from pdf into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guzma\\anaconda3\\Lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load PDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Vector database\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "# Llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ.clear()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 3112 characters in your document\n"
     ]
    }
   ],
   "source": [
    "#use your file \n",
    "loader = PyPDFLoader(\"../ruy.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 4 documents\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "print (f'Now you have {len(texts)} documents')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedings and upload to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'),chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key= os.getenv('PINECONE_API_KEY'),  # find at app.pinecone.io\n",
    "    environment= os.getenv('PINECONE_ENVIRONMENT')   # next to api key in console\n",
    ")\n",
    "index = 'digital-twin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from vector database with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pinecone.Index(index)\n",
    "text_field = \"text\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    idx,\n",
    "    embeddings,\n",
    "    text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prompt templates for data within the CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruy has experience related to DevOps through his Major League Hacking Fellowship and his role as a volunteer student at IBM. Here is an overview of his DevOps experience:\n",
      "\n",
      "- Major League Hacking Fellowship (May 2022 - Aug 2022):\n",
      "  - Completed 12 weeks of curriculum-based learning covering core Production Engineering topics.\n",
      "  - Developed an open-source personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API.\n",
      "  - Automated testing and deployment using CI/CD with GitHub Actions.\n",
      "  - Set up monitoring environments using Prometheus and Grafana.\n",
      "\n",
      "- Volunteer Student at IBM (Feb 2023 - Jun 2023):\n",
      "  - Worked as a full-stack developer of a web dashboard aimed to manage certifications within IBM's employees.\n",
      "  - Developed a web server using Ruby on Rails connected to an Azure MySQL database.\n",
      "  - Developed API tests using RSpec within the Rails project.\n",
      "  - Setup testing and deployment using Docker and CI/CD with GitHub Actions.\n",
      "\n",
      "Here is a detailed list of technologies used in Ruy's DevOps experience:\n",
      "\n",
      "- Major League Hacking Fellowship:\n",
      "  - Programming Languages: Python\n",
      "  - Web Framework: Flask\n",
      "  - Templating Engine: Jinja\n",
      "  - CSS Framework: Tailwind CSS\n",
      "  - Database: MySQL\n",
      "  - Web Server: Nginx\n",
      "  - Testing: Unittest\n",
      "  - Containerization: Docker\n",
      "  - CI/CD: GitHub Actions\n",
      "  - Monitoring: Prometheus, Grafana\n",
      "\n",
      "- Volunteer Student at IBM:\n",
      "  - Programming Language: Ruby\n",
      "  - Web Framework: Ruby on Rails\n",
      "  - Database: Azure MySQL\n",
      "  - Testing: RSpec\n",
      "  - Containerization: Docker\n",
      "  - CI/CD: GitHub Actions\n",
      "\n",
      "Please note that these are the specific technologies mentioned in Ruy's experience that are related to DevOps. He may have additional skills and experiences not mentioned here.\n"
     ]
    }
   ],
   "source": [
    "query = \"What experience does Ruy have related to devops? Give me an overview and a detailed list of technologies used in his devops experience\"\n",
    "response = qa.run(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
