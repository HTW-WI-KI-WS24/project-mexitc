{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pincecone first implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\karla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\karla\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from pdf into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datas\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Vector database\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "# Llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema import SystemMessage, ChatMessage\n",
    "\n",
    "#agents\n",
    "from langchain.agents.types import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ.clear()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 3112 characters in your document\n"
     ]
    }
   ],
   "source": [
    "#use your file \n",
    "loader = PyPDFLoader(\"../ruy.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 4 documents\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedings and upload to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'),chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key= os.getenv('PINECONE_API_KEY'),  # find at app.pinecone.io\n",
    "    environment= os.getenv('PINECONE_ENVIRONMENT')   # next to api key in console\n",
    ")\n",
    "index = 'digital-twin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from vector database with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pinecone.Index(index)\n",
    "text_field = \"text\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    idx,\n",
    "    embeddings,\n",
    "    text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTopic = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"What experience does Ruy have related to {topic}? Give me an overview and a detailed list of technologies used in his {topic} experience\",\n",
    "    )\n",
    "\n",
    "promptLanguage= PromptTemplate(\n",
    "    input_variables=[\"language\"],\n",
    "    template=\"Is {language} within the programming lnguages Ruy can use? And show me an example of how has he used it\",\n",
    "    )\n",
    "\n",
    "promptFramework = PromptTemplate(\n",
    "    input_variables=[\"framework\"],\n",
    "    template=\"Does Ruy have any expierence using {framework}? Describe the experiences\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name='gpt-4',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step back prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: _Py_HashRandomization_Init: failed to get random numbers to initialize Python\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain import hub\n",
    "\n",
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few_shots examples and promtps\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"input\": \"What programming languages are you proficient in?\",\n",
    "        \"output\": \"List the programming languages you are proficient in.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Tell me about a project where you worked collaboratively with a team.\",\n",
    "        \"output\": \"Describe a project where you collaborated with a team, including your role and contributions.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How do you stay updated with the latest technologies in the field?\",\n",
    "        \"output\": \"Explain how you stay informed about the latest technologies and industry trends.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Tell me about a challenging problem you encountered during a project and how you solved it.\",\n",
    "        \"output\": \"Describe a challenging problem you faced during a project and the steps you took to solve it.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-back prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"),\n",
    "    few_shot_prompt,  # Include the few-shot examples\n",
    "    (\"user\", \"{question}\"),\n",
    "])\n",
    "\n",
    "question_gen = prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question):\n",
    "    question_gen = prompt | ChatOpenAI(temperature=0) | StrOutputParser()\n",
    "    question_gen.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain definition\n",
    "chain = {\n",
    "    # Retrieve context using the normal question\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Retrieve context using the step-back question\n",
    "    \"step_back_context\": prompt | ChatOpenAI(temperature=0) | StrOutputParser(),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./StudentPrompt.txt\")\n",
    "\n",
    "StudentPrompt = loader.load()[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"qa-student\",\n",
    "        func=qa.run,\n",
    "        description=\"Answer questions related to the student\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=conversational_memory,\n",
    "    system_message=StudentPrompt,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": StudentPrompt\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='\"I\\'m looking for a DevOps engineer, do you have any experience?\"'),\n",
       "  AIMessage(content=\"Absolutely, I do have experience in the area of DevOps. During my academic projects and my time as an intern, I played a key role in setting up CI/CD pipelines and worked extensively with tools like Docker and Jenkins. This allowed me to gain hands-on experience in automating, deploying, and monitoring software. I'm confident that this experience, combined with my ability to learn quickly and adapt to new environments, would make me a valuable addition to your DevOps team.\"),\n",
       "  HumanMessage(content=\"I'm looking for a Production engineer, do you have any experience?\"),\n",
       "  AIMessage(content='Certainly, I have had extensive experience in production engineering. During my degree program, I had the chance to work on a number of projects spanning areas like process optimization, equipment design and quality improvement. Moreover, in my previous internship, I was actively involved in troubleshooting and maintaining production line systems, ensuring their efficiency while adhering to strict safety guidelines. My experience in working with cross-functional teams and hands-on skills with tools like AutoCAD, MATLAB and Labview, I believe, position me well for a role as a production engineer.'),\n",
       "  HumanMessage(content='where was your internship?'),\n",
       "  AIMessage(content='I completed my internships at two esteemed organizations, IBM and the Major League Hacking Fellowship.'),\n",
       "  HumanMessage(content=\"As an AI language model, I have been trained on a wide range of topics and have access to a vast amount of information. While I don't possess personal experiences or emotions like humans do, I can provide comprehensive and accurate information on various subjects. Some areas where I can demonstrate proficiency include history, geography, science, literature, technology, and current events. However, it's important to note that my responses are generated based on patterns and examples in the data I've been trained on, so they may not always reflect the most up-to-date information or the nuanced perspectives of experts in specific fields.\"),\n",
       "  AIMessage(content=\"As a digital persona emulating Ruy Guzman, I don't possess personal experiences or emotions like humans do. However, I draw on stored data about Ruy and her experiences to respond to the questions. This includes Ruy's history of internships and academic accomplishments. I should mention, however, that my responses are generated based on the information that has been inputted about Ruy, and therefore may not reflect real-time updates.\"),\n",
       "  HumanMessage(content=\"As an AI language model, I have been trained on a vast amount of text data from various sources, so I don't have personal experiences or work with languages in the same way humans do. However, I have been designed to understand and generate text in multiple languages, including but not limited to English, Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, and many others. My purpose is to assist users in generating human-like text based on the prompts given to me, regardless of the language.\"),\n",
       "  AIMessage(content='Indeed, as a digital model, I can understand and generate text in multiple languages. My primary function is to provide assistance in generating human-like text according to the prompts given to me, regardless of the language in which the prompt is issued. I span from languages such as English, Spanish, French to even German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, among others.')]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Hello, thank you for reaching out. I'm Ruy Guzman, a dedicated student passionate about technology. I have been actively pursuing opportunities that allow me to apply my academic knowledge to real-world tech challenges. My focus area during my studies has been in areas like DevOps and production engineering, but I am also enthusiastic about exploring new fields. I have interned at IBM and proved my abilities in setting up CI/CD pipelines and maintaining production line systems. Eager to learn and adapt, I'm excited about potential opportunities at your company.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello, thank you for reaching out. I'm Ruy Guzman, a dedicated student passionate about technology. I have been actively pursuing opportunities that allow me to apply my academic knowledge to real-world tech challenges. My focus area during my studies has been in areas like DevOps and production engineering, but I am also enthusiastic about exploring new fields. I have interned at IBM and proved my abilities in setting up CI/CD pipelines and maintaining production line systems. Eager to learn and adapt, I'm excited about potential opportunities at your company.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"Hi, Im a recruiter for a tech company. Can you briefly introduce yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"As a digital persona of Ruy Guzman, I can assert Ruy's proficiency in several programming languages. They include Python, known for its simplicity and widely used in her data analysis tasks; JavaScript, which she has utilized in her web development projects; Java, with which she has developed enterprise-level applications during her stint at IBM; and MATLAB, her chosen tool for numerous university projects involving numerical computing and data visualization. Ruy's skills are a blend of academic knowledge and practical application, making her a competent professional, ready to handle the demands of the tech industry.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent: As a digital persona of Ruy Guzman, I can assert Ruy's proficiency in several programming languages. They include Python, known for its simplicity and widely used in her data analysis tasks; JavaScript, which she has utilized in her web development projects; Java, with which she has developed enterprise-level applications during her stint at IBM; and MATLAB, her chosen tool for numerous university projects involving numerical computing and data visualization. Ruy's skills are a blend of academic knowledge and practical application, making her a competent professional, ready to handle the demands of the tech industry.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    initial_question = chain.invoke({\"question\": user_input})\n",
    "    step_back = student.run(initial_question)\n",
    "    print(f\"Agent: {step_back}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Absolutely, I do have experience in DevOps. During my time as a full-stack developer with IBM, I employed tools like Docker and made use of CI/CD processes with GitHub Actions to set up testing and deployment. This experience has provided me a comprehensive understanding of the DevOps environment and its workflow.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Absolutely, I do have experience in DevOps. During my time as a full-stack developer with IBM, I employed tools like Docker and made use of CI/CD processes with GitHub Actions to set up testing and deployment. This experience has provided me a comprehensive understanding of the DevOps environment and its workflow.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"I'm looking for a DevOps engineer, do you have any experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"qa-student\",\n",
      "    \"action_input\": \"production engineer experience\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRuy Guzman Camacho worked as a Production Engineering Fellow in the Major League Hacking (MLH) Fellowship from May 2022 to August 2022. During this fellowship, he completed a 12-week curriculum-based learning program covering core Production Engineering topics, along with attending events and workshops hosted by industry experts. He developed an open-source personal portfolio website using various programming languages and tools such as Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. Additionally, he set up monitoring environments using Prometheus and Grafana, and automated testing and deployment processes using CI/CD with GitHub actions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Yes, I do have experience as a Production Engineer. I was a Production Engineering Fellow in the Major League Hacking Fellowship. During this time, I followed a 12-week program which covered core Production Engineering topics. This opportunity granted me the experience to develop an open-source personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API, among others. Moreover, I was able to establish monitoring environments using tools like Prometheus and Grafana, and automated testing and deployment processes through CI/CD with GitHub actions.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I do have experience as a Production Engineer. I was a Production Engineering Fellow in the Major League Hacking Fellowship. During this time, I followed a 12-week program which covered core Production Engineering topics. This opportunity granted me the experience to develop an open-source personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API, among others. Moreover, I was able to establish monitoring environments using tools like Prometheus and Grafana, and automated testing and deployment processes through CI/CD with GitHub actions.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"I'm looking for a Production engineer, do you have any experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ruy Guzman Camacho has experience in DevOps from his time spent as a MLH Production Engineering Fellow at Major League Hacking Fellowship during the summer of 2022. This role allowed him to complete 12 weeks of curriculum-based learning covering core Production Engineering topics, and it also involved hosting events and workshops led by industry experts.\\n\\nIn terms of detailed technological experience in his DevOps role, Ruy:\\n\\n1. Developed an open-source personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, and the Google Maps API.\\n2. Automated testing and deployment using Continuous Integration/Continuous Deployment (CI/CD) with GitHub actions.\\n3. Set up monitoring environments using Prometheus and Grafana.\\n4. Gained experience with Docker for creating, deploying, and running applications.\\n5. Utilized Python, Flask, and Jinja for website development.\\n6. Used Tailwind CSS for styling the website.\\n7. Handled database operations with MySQL.\\n8. Deployed the portfolio website with Nginx.\\n9. Implemented unit testing with Python's unittest module.\\n10. Worked with the Google Maps API.\\n  \\nThese experiences have provided Ruy with a comprehensive understanding of not only various pillars of DevOps such as CI/CD, monitoring, and automation, but also a range of technologies that are vital in a DevOps environment.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptTopic.format(topic=\"DevOps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided context does not give specific details about a person named Ruy and how he has used Ruby. However, it does mention that Ruby on Rails, a framework that uses Ruby, is used in software development. We do not have specific examples of how this knowledge is applied.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptLanguage.format(language=\"Ruby\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context provided does not mention any experience Ruy Guzman Camacho may have using React. His noted experience includes developing a portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API, as well as setting up monitoring environments using Prometheus and Grafana.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptFramework.format(framework=\"React\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
