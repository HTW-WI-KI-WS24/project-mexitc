{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pincecone first implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\karla\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\karla\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from pdf into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datas\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Vector database\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "# Llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema import SystemMessage, ChatMessage\n",
    "\n",
    "#agents\n",
    "from langchain.agents.types import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ.clear()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 3112 characters in your document\n"
     ]
    }
   ],
   "source": [
    "#use your file \n",
    "loader = PyPDFLoader(\"../ruy.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 4 documents\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedings and upload to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'),chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key= os.getenv('PINECONE_API_KEY'),  # find at app.pinecone.io\n",
    "    environment= os.getenv('PINECONE_ENVIRONMENT')   # next to api key in console\n",
    ")\n",
    "index = 'digital-twin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from vector database with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pinecone.Index(index)\n",
    "text_field = \"text\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    idx,\n",
    "    embeddings,\n",
    "    text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTopic = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"What experience does Ruy have related to {topic}? Give me an overview and a detailed list of technologies used in his {topic} experience\",\n",
    "    )\n",
    "\n",
    "promptLanguage= PromptTemplate(\n",
    "    input_variables=[\"language\"],\n",
    "    template=\"Is {language} within the programming lnguages Ruy can use? And show me an example of how has he used it\",\n",
    "    )\n",
    "\n",
    "promptFramework = PromptTemplate(\n",
    "    input_variables=[\"framework\"],\n",
    "    template=\"Does Ruy have any expierence using {framework}? Describe the experiences\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./StudentPrompt.txt\")\n",
    "\n",
    "StudentPrompt = loader.load()[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"qa-student\",\n",
    "        func=qa.run,\n",
    "        description=\"Answer questions related to the student\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=conversational_memory,\n",
    "    system_message=StudentPrompt,\n",
    "    agent_kwargs={\n",
    "        \"system_message\": StudentPrompt\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step back prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few_shots examples and promtps\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"input\": \"What programming languages are you proficient in?\",\n",
    "        \"output\": \"List the programming languages you are proficient in.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Tell me about a project where you worked collaboratively with a team.\",\n",
    "        \"output\": \"Describe a project where you collaborated with a team, including your role and contributions.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How do you stay updated with the latest technologies in the field?\",\n",
    "        \"output\": \"Explain how you stay informed about the latest technologies and industry trends.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Tell me about a challenging problem you encountered during a project and how you solved it.\",\n",
    "        \"output\": \"Describe a challenging problem you faced during a project and the steps you took to solve it.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-back prompt template\n",
    "step_back_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\"),\n",
    "    few_shot_prompt,  # Include the few-shot examples\n",
    "    (\"user\", \"{question}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_back_retriever(query):\n",
    "    return step_back_prompt | ChatOpenAI(temperature=0) | StrOutputParser() | retriever(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain definition\n",
    "chain = {\n",
    "    # Retrieve context using the normal question\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Retrieve context using the step-back question\n",
    "    \"step_back_context\": RunnableLambda(lambda x: x['question']) | step_back_retriever,\n",
    "    # Pass on the question\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{ \"action\": \"qa-student\", \"action_input\": \"Can you briefly introduce yourself?\" }\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI am an AI language model developed by OpenAI, known as GPT-3. I don't have a personal name or bio, but I can provide information and answer your questions to the best of my abilities. My purpose is to assist users in generating human-like text based on the prompts given to me. How can I assist you today?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{ \"action\": \"Final Answer\", \"action_input\": \"As an AI language model, I am a versatile tool that can assist with a wide range of tasks. I can provide information, answer questions, and engage in conversations on various topics, including technology and job searching. If you have any specific questions or need assistance with anything related to recruiting or the tech industry, please let me know and I'll be happy to help!\" }\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an AI language model, I am a versatile tool that can assist with a wide range of tasks. I can provide information, answer questions, and engage in conversations on various topics, including technology and job searching. If you have any specific questions or need assistance with anything related to recruiting or the tech industry, please let me know and I'll be happy to help!\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"Hi, Im a recruiter for a tech company. Can you briefly introduce yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"qa-student\",\n",
      "  \"action_input\": \"Do you have any experience as a DevOps engineer?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the provided context, there is no explicit mention of experience as a DevOps engineer. The individual has experience in software development, full-stack development, production engineering, and has used tools and technologies related to DevOps such as Docker, CI/CD with GitHub Actions, and monitoring environments with Prometheus and Grafana. However, without specific information about working as a DevOps engineer, it cannot be concluded that they have direct experience in that role.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"While I don't have specific experience as a DevOps engineer, I have experience in software development and have worked with tools and technologies related to DevOps such as Docker, CI/CD with GitHub Actions, and monitoring environments with Prometheus and Grafana. I am confident in my ability to learn and adapt to new challenges, and I believe my skills as a proactive and dedicated student make me a valuable candidate for a DevOps engineering role.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"While I don't have specific experience as a DevOps engineer, I have experience in software development and have worked with tools and technologies related to DevOps such as Docker, CI/CD with GitHub Actions, and monitoring environments with Prometheus and Grafana. I am confident in my ability to learn and adapt to new challenges, and I believe my skills as a proactive and dedicated student make me a valuable candidate for a DevOps engineering role.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"I'm looking for a DevOps engineer, do you have any experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"qa-student\",\n",
      "    \"action_input\": \"Do I have any experience as a Production engineer?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mYes, you have experience as a Production Engineer. You participated in the Major League Hacking Fellowship as a Production Engineering Fellow, where you completed a 12-week curriculum-based learning program on core Production Engineering topics. As part of this fellowship, you developed a personal portfolio website using various technologies such as Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. You also gained experience in automated testing and deployment using CI/CD with GitHub Actions, and in setting up monitoring environments using Prometheus and Grafana.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Yes, I do have experience as a Production Engineer. I participated in the Major League Hacking Fellowship as a Production Engineering Fellow, where I gained hands-on experience in core Production Engineering topics. I also developed a personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. Additionally, I have experience in automated testing and deployment using CI/CD with GitHub Actions, as well as setting up monitoring environments using Prometheus and Grafana.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I do have experience as a Production Engineer. I participated in the Major League Hacking Fellowship as a Production Engineering Fellow, where I gained hands-on experience in core Production Engineering topics. I also developed a personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API. Additionally, I have experience in automated testing and deployment using CI/CD with GitHub Actions, as well as setting up monitoring environments using Prometheus and Grafana.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.run(\"I'm looking for a Production engineer, do you have any experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruy Guzman Camacho has experience in DevOps through his Major League Hacking Fellowship and his volunteer work at IBM. Here is an overview of his DevOps experience:\n",
      "\n",
      "1. Major League Hacking Fellowship (May 2022-Aug 2022):\n",
      "   - Completed 12 weeks of curriculum-based learning on core Production Engineering topics.\n",
      "   - Developed an open-source personal portfolio website using Python, Flask, Jinja, Tailwind CSS, MySQL, Nginx, Unittest, Docker, and the Google Maps API.\n",
      "   - Automated testing and deployment using CI/CD with GitHub Actions.\n",
      "   - Set up monitoring environments using Prometheus and Grafana.\n",
      "\n",
      "2. IBM (Feb 2023 – Jun 2023):\n",
      "   - Worked as a full-stack developer on a web dashboard aimed at managing certifications within IBM's employees.\n",
      "   - Developed a web server using Ruby on Rails, connected to an Azure MySQL database.\n",
      "   - Developed API tests using RSpec within the Rails project.\n",
      "   - Set up testing and deployment using Docker and CI/CD with GitHub Actions.\n",
      "   - Developed multiple components on the front-end using TypeScript in the React JS framework.\n",
      "\n",
      "Detailed list of technologies used in Ruy's DevOps experience:\n",
      "\n",
      "- Programming Languages: Python, Ruby, TypeScript\n",
      "- Web Frameworks: Flask, Ruby on Rails, React JS\n",
      "- Database: MySQL, Azure MySQL\n",
      "- Testing: Unittest, RSpec\n",
      "- Version Control: Git\n",
      "- Containerization: Docker\n",
      "- CI/CD: GitHub Actions\n",
      "- Monitoring: Prometheus, Grafana\n",
      "- Cloud Services: Microsoft Azure\n",
      "- Other Tools: VS Code, Visual Studio, Heroku\n",
      "\n",
      "Please note that this is a summary of Ruy's experience and the technologies mentioned are the ones specifically mentioned in the provided context. There may be additional technologies or tools that Ruy has experience with but are not mentioned here.\n"
     ]
    }
   ],
   "source": [
    "qa.run(promptTopic.format(topic=\"DevOps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, Ruby is one of the programming languages that Ruy is familiar with. He has used Ruby on Rails to develop a web dashboard for IBM to manage certifications within the company's employees. The web server he developed was connected to an Azure MySQL database. Additionally, he developed API tests using RSpec within the Rails project.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptLanguage.format(language=\"Ruby\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, Ruy has experience using React. In his Major League Hacking Fellowship, he worked on a project called Geriatrik/Geriatrik-API, where he served as a full-stack developer. He developed authentication components for the application, defining endpoints on the API and implementing authorization middleware. This project involved using React as the front-end framework.\\n\\nAdditionally, in his Relevant Coursework section, Ruy mentions taking a course on Software Development, which included learning React.js. Although specific details about his experience with React.js in this course are not provided, it indicates that he has knowledge and understanding of the framework.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(promptFramework.format(framework=\"React\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
